# -- Namespace of the main rook operator
operatorNamespace: rook-ceph

# -- Cluster ceph.conf override
configOverride: |
  [global]
  osd pool default size = 3
  osd pool default min size = 2

# Installs a debugging toolbox deployment
toolbox:
  # -- Enable Ceph debugging pod deployment
  enabled: true
  # -- Toolbox container security context
  containerSecurityContext:
    runAsNonRoot: true
    runAsUser: 2016
    runAsGroup: 2016
    capabilities:
      drop: ["ALL"]
  # -- Toolbox resources
  resources:
    limits:
      cpu: "500m"
      memory: "1Gi"
    requests:
      cpu: "100m"
      memory: "128Mi"

monitoring:
  # -- Enable Prometheus integration
  enabled: true
  # -- Whether to disable the metrics reported by Ceph
  metricsDisabled: false
  # -- Whether to create the Prometheus rules for Ceph alerts
  createPrometheusRules: false

# -- Create & use PSP resources (keep upstream default)
pspEnable: false

cephClusterSpec:
  cephVersion:
    image: quay.io/ceph/ceph:v18.2.4
    allowUnsupported: false
  dataDirHostPath: /var/lib/rook
  
  mon:
    count: 1
    allowMultiplePerNode: true
  mgr:
    count: 1
    allowMultiplePerNode: true
    modules:
    - name: rook
      enabled: true
  dashboard:
    enabled: true
    ssl: true
  monitoring:
    enabled: true
    metricsDisabled: false
    exporter:
      perfCountersPrioLimit: 5
      statsPeriodSeconds: 5
  network:
    connections:
      encryption:
        enabled: true
      requireMsgr2: true
      compression:
        enabled: false
  crashCollector:
    disable: false
  disruptionManagement:
    managePodBudgets: true
    osdMaintenanceTimeout: 30
    pgHealthCheckTimeout: 0
  logCollector:
    enabled: true
    periodicity: daily
    maxLogSize: 500M
  upgradeOSDRequiresHealthyPGs: false
  waitTimeoutForHealthyOSDInMinutes: 10
  priorityClassNames:
    mon: system-node-critical
    osd: system-node-critical
    mgr: system-cluster-critical
  cleanupPolicy:
    confirmation: ""
    sanitizeDisks:
      method: quick
      dataSource: zero
      iteration: 1
    allowUninstallWithVolumes: false
  storage:
    useAllNodes: true
    useAllDevices: true
    # deviceFilter: "^sd[b-z]"
    config:
      osdsPerDevice: "1"
      encryptedDevice: "true" 
  
  resources:
    mgr:
      limits:
        memory: "1Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
    osd:
      limits:
        memory: 8192Mi
      requests:
        cpu: "1000m"
        memory: 8192Mi
    mon:
      limits:
        memory: "2Gi"
      requests:
        cpu: "1000m"
        memory: "1Gi"
  
  placement:
    all:
# plan with swisscom based on architecture
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: storage-node
              operator: In
              values:
              - "true"
  healthCheck:
    daemonHealth:
      mon:
        disabled: false
        interval: 45s
      osd:
        disabled: false
        interval: 60s
      status:
        disabled: false
        interval: 60s
    livenessProbe:
      mon:
        disabled: false
      mgr:
        disabled: false
      osd:
        disabled: false
    startupProbe:
      mon:
        disabled: false
      mgr:
        disabled: false
      osd:
        disabled: false
# Block pools configuration
cephBlockPools:
- name: ceph-blockpool
  spec:
    failureDomain: host
    replicated:
      size: 3
  storageClass:
    enabled: true
    name: ceph-block
    isDefault: true
    reclaimPolicy: Delete
    allowVolumeExpansion: true
    parameters:
      imageFormat: "2"
      imageFeatures: layering
      csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
      csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
      csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
      csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
      csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
      csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph

# Filesystem configuration
cephFileSystems:
- name: ceph-filesystem
  spec:
    metadataPool:
      replicated:
        size: 3
    dataPools:
    - name: data0
      replicated:
        size: 3
    preserveFilesystemOnDelete: true
    metadataServer:
      activeCount: 1
      activeStandby: true
      resources:
        limits:
          cpu: "2000m"
          memory: "4Gi"
        requests:
          cpu: "1000m"
          memory: "4Gi"
  storageClass:
    enabled: true
    name: ceph-filesystem
    reclaimPolicy: Delete
    parameters:
      csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
      csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
      csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
      csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
      csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
      csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph

# Remove object store configuration entirely
cephObjectStores: []
